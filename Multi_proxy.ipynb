{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('===== content-type : ', 'text/html; charset=utf-8')\n",
      "(\"===== headers.getparam('charset') : \", 'utf-8')\n",
      "('===== get proxy page proxy_list:,type ', [], <type 'list'>)\n",
      "有效代理个数为 : 5\n",
      "('URL is :', 'https://youtu.be/RysyB_Zcjlo')\n",
      "输入次数:1\n",
      "次数确认为 1\n",
      "('=== start to get blog list from url: ', <urllib2.Request instance at 0x104353518>)\n",
      "启动!!!!!!!!!!!!!!!!!!!!\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?0')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?1')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?2')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?3')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?4')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?5')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?6')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?7')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?8')\n",
      "('===== each_link', 'https://youtu.be/RysyB_Zcjlo?9')\n",
      "当前访问 Blog h 第 0 次\n",
      "当前访问 Blog t 第 0 次当前访问 Blog t 第 0 次\n",
      "\n",
      "智能切换代理：203.91.121.76:3128当前访问 Blog p 第 0 次智能切换代理：221.211.193.51:80智能切换代理：180.168.179.193:8080\n",
      "\n",
      "当前访问 Blog : 第 0 次当前访问 Blog / 第 0 次 \n",
      "\n",
      "当前访问 Blog / 第 0 次智能切换代理：180.168.179.193:8080\n",
      "\n",
      "当前访问 Blog y 第 0 次当前访问 Blog o 第 0 次\n",
      "当前访问 Blog s 第 0 次\n",
      "\n",
      "智能切换代理：120.7.84.59:8118 \n",
      "当前访问 Blog t 第 0 次当前访问 Blog u 第 0 次当前访问 Blog . 第 0 次当前访问 Blog e 第 0 次当前访问 Blog b 第 0 次 智能切换代理：120.7.84.59:8118\n",
      "智能切换代理：221.211.193.51:80当前访问 Blog / 第 0 次\n",
      "智能切换代理：180.168.179.193:8080智能切换代理：221.211.193.51:80\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "当前访问 Blog _ 第 0 次\n",
      "智能切换代理：180.168.179.193:8080\n",
      "\n",
      "当前访问 Blog o 第 0 次\n",
      "\n",
      "智能切换代理：180.168.179.193:8080智能切换代理：203.91.121.76:3128智能切换代理：180.168.179.193:8080智能切换代理：120.7.84.59:8118智能切换代理：203.91.121.76:3128\n",
      "智能切换代理：221.211.193.51:80\n",
      " 智能切换代理：120.7.84.59:8118\n",
      "当前访问 Blog B 第 0 次 \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 当前访问 Blog y 第 0 次\n",
      "智能切换代理：本机\n",
      "当前访问 Blog u 第 0 次  当前访问 Blog R 第 0 次\n",
      "当前访问 Blog s 第 0 次\n",
      "当前访问 Blog y 第 0 次\n",
      "智能切换代理：180.168.179.193:8080\n",
      "当前访问 Blog j 第 0 次当前访问 Blog l 第 0 次智能切换代理：180.168.179.193:8080\n",
      "智能切换代理：本机\n",
      "\n",
      "\n",
      "智能切换代理：221.211.193.51:80\n",
      "\n",
      "智能切换代理：本机\n",
      "智能切换代理：本机智能切换代理：203.91.121.76:3128当前访问 Blog c 第 0 次\n",
      "智能切换代理：203.91.121.76:3128\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " 当前访问 Blog Z 第 0 次智能切换代理：180.168.179.193:8080\n",
      "\n",
      "智能切换代理：221.211.193.51:80\n",
      "完成任务!!!!!!!!!!!!!!!!!!!!\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# -*- coding=utf-8 -*-\n",
    "\n",
    "# 刷 CSDN 博客访问量\n",
    "import urllib\n",
    "import urllib2\n",
    "import re,random\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "time_out = 10 # 全局变量 10 秒超时时间\n",
    "count = 0\n",
    "proxies = [None]\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "             'Accept':'text/html;q=0.9,*/*;q=0.8',\n",
    "             'Accept-Charset':'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "             #'Accept-Encoding':'gzip',\n",
    "             'Connection':'close',\n",
    "             'Referer':None #注意如果依然不能抓取的话，这里可以设置抓取网站的host\n",
    "             }\n",
    "def get_proxy():\n",
    "    # 使用全局变量,修改之\n",
    "    global proxies\n",
    "    try:\n",
    "        url = 'http://www.xicidaili.com/'\n",
    "        #url = 'http://www.google.com/'\n",
    "        req_header = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "             'Accept':'text/html;q=0.9,*/*;q=0.8',\n",
    "             'Accept-Charset':'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "             #'Accept-Encoding':'gzip',\n",
    "             'Connection':'close',\n",
    "             'Referer':None #注意如果依然不能抓取的话，这里可以设置抓取网站的host\n",
    "             }\n",
    "        req_timeout = 10\n",
    "        req = urllib2.Request(url,None,req_header)\n",
    "        resp = urllib2.urlopen(req,None,req_timeout)\n",
    "        html = resp.read()\n",
    "     \n",
    "        #req.add_header(\"User-Agent\",\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_2) AppleWebKit/537.36 \n",
    "        #  (KHTML, like Gecko) Chrome/47.0.2526.106 Safari/537.36\")\n",
    "\n",
    "        response = urllib2.urlopen(req)\n",
    "        the_page = response.read()\n",
    "        #req = urllib2.urlopen('http://www.xicidaili.com/',None,headers)\n",
    "        #req = urllib2.Request(\"http://www.xicidaili.com/\", headers=headers)\n",
    "        #req  = urllib2.urlopen('http://www.xicidaili.com/')\n",
    "        #print(\"===== start to get proxy list\",req.read())\n",
    "        \n",
    "    except urllib2.URLError,e:\n",
    "        print('无法获取代理信息!')\n",
    "        print e.reason\n",
    "        print e.reason[0]\n",
    "        print e.reason[1]\n",
    "        return\n",
    "    \n",
    "    response =urllib2.urlopen(req)\n",
    "    print (\"===== content-type : \",response.headers['content-type'] )\n",
    "    print (\"===== headers.getparam('charset') : \",response.headers.getparam('charset') )\n",
    "    \n",
    "    result = response.read().decode('utf-8')\n",
    "    #html = response.read().decode('utf-8')\n",
    "    '''\n",
    "    <tr class=\"odd\">\n",
    "      <td class=\"country\"><img src=\"http://fs.xicidaili.com/images/flag/cn.png\" alt=\"Cn\"></td>\n",
    "      <td>218.18.61.173</td>\n",
    "      <td>8118</td>\n",
    "      <td>\n",
    "        <a href=\"/2017-10-01/guangdong\">广东深圳市福田区</a>\n",
    "      </td>\n",
    "      <td class=\"country\">高匿</td>\n",
    "      <td>HTTP</td>\n",
    "      <td class=\"country\">\n",
    "        <div title=\"0.16秒\" class=\"bar\">\n",
    "          <div class=\"bar_inner fast\" style=\"width:97%\">\n",
    "            \n",
    "          </div>\n",
    "        </div>\n",
    "      </td>\n",
    "      <td class=\"country\">\n",
    "        <div title=\"0.032秒\" class=\"bar\">\n",
    "          <div class=\"bar_inner fast\" style=\"width:96%\">\n",
    "            \n",
    "          </div>\n",
    "        </div>\n",
    "      </td>\n",
    "      \n",
    "      <td>3小时</td>\n",
    "      <td>17-10-01 04:09</td>\n",
    "    </tr>\n",
    "    '''\n",
    "    #print(\"===== get proxy page ,type : \",result,type(result) )\n",
    "    \n",
    "    p = re.compile(r'''<tr\\sclass[^>]*>\\s+\n",
    "                                    <td>.+</td>\\s+\n",
    "                                    <td>(.*)?</td>\\s+\n",
    "                                    <td>(.*)?</td>\\s+\n",
    "                                    <td>(.*)?</td>\\s+\n",
    "                                    <td>(.*)?</td>\\s+\n",
    "                                    <td>(.*)?</td>\\s+\n",
    "                                    <td>(.*)?</td>\\s+\n",
    "                                </tr>''',re.VERBOSE)\n",
    "    proxy_list = p.findall(result)\n",
    "    \n",
    "    #proxy_list = re.findall(r'<tr class=\"odd\"><</tr>',result, re.M|re.I|re.S)\n",
    "    \n",
    "    \n",
    "    print(\"===== get proxy page proxy_list:,type \",proxy_list,type(proxy_list))\n",
    "    proxies.append('221.211.193.51:80')\n",
    "    proxies.append('120.7.84.59:8118')\n",
    "    proxies.append('203.91.121.76:3128')\n",
    "    proxies.append('180.168.179.193:8080')\n",
    "    for each_proxy in proxy_list[1:]:\n",
    "        if each_proxy[4] == 'HTTP':\n",
    "            proxies.append(each_proxy[0]+':'+each_proxy[1])\n",
    "            \n",
    "def change_proxy():\n",
    "    # 随机从序列中取出一个元素\n",
    "    proxy = random.choice(proxies)\n",
    "    # 判断元素是否合理\n",
    "    if proxy == None:\n",
    "        proxy_support =urllib2.ProxyHandler({})\n",
    "    else:\n",
    "        proxy_support = urllib2.ProxyHandler({'http':proxy})\n",
    "    opener = urllib2.build_opener(proxy_support)\n",
    "    opener.addheaders = [('User-Agent',headers['User-Agent'])]\n",
    "    urllib2.install_opener(opener)\n",
    "    print('智能切换代理：%s' % ('本机' if proxy==None else proxy))\n",
    "def get_req(url):\n",
    "    # 先伪造一下头部吧,使用字典\n",
    "    blog_eader = {\n",
    "                'User-Agent':'Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.152 Safari/537.36',\n",
    "                'Host':'blog.csdn.net',\n",
    "                'Referer':'http://blog.csdn.net/',\n",
    "                'GET':url\n",
    "                } \n",
    "    #req = urllib2.urlopen(url,headers = blog_eader)\n",
    "    req = urllib2.Request(url, headers=headers)\n",
    "    return req\n",
    "# 访问 博客\n",
    "def look_blog(url):\n",
    "    # 切换一下IP\n",
    "    change_proxy()\n",
    "    req = get_req(url)\n",
    "    try:\n",
    "        urllib2.urlopen(req,timeout = time_out)\n",
    "    except:\n",
    "        return\n",
    "    else:\n",
    "        print('访问成功!')\n",
    "# 迭代访问\n",
    "def click_blog(url):\n",
    "    for i in range(0,count):\n",
    "        if(i == count):\n",
    "            break\n",
    "        print('当前访问 Blog %s 第 %d 次' % (url,i))\n",
    "        look_blog(url)\n",
    "# 获取博客的文章链表\n",
    "def get_blog_list(url):\n",
    "    req = get_req(url)\n",
    "    try:\n",
    "        print(\"=== start to get blog list from url: \",req)\n",
    "        \n",
    "        response = urllib2.urlopen(req)\n",
    "    except:\n",
    "        print('无法挽回的错误')\n",
    "        return None\n",
    "    '''\n",
    "    # 由于 Csdn 是 utf-8 所以不需要转码\n",
    "    html = response.read()\n",
    "    # 存储一个正则表达式 规则\n",
    "    regx = '<span class=\"link_title\"><a href=\"(.+?)\">'\n",
    "    pat = re.compile(regx)\n",
    "    # 其实这里 写作 list1 = re.findall('<span class=\"link_title\"><a href=\"(.+?)\">',str(html)) 也是一样的结果\n",
    "    blog_list = re.findall(pat,str(html))\n",
    "    return blog_list\n",
    "    '''\n",
    "    return \"https://youtu.be/RysyB_Zcjlo\"\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    global count\n",
    "    # 基本参数初始化\n",
    "    # 获取代理\n",
    "    get_proxy()\n",
    "    print('有效代理个数为 : %d' % len(proxies))\n",
    "    #blogurl = input('输入blog链接:')\n",
    "    # 这个地方原本是我的默认输入偷懒用的\n",
    "    blogurl = 'https://youtu.be/RysyB_Zcjlo'\n",
    "    if len(blogurl) == 0:\n",
    "        #blogurl = 'http://blog.csdn.net/bkxiaoc/'\n",
    "        blogurl = 'https://youtu.be/RysyB_Zcjlo'\n",
    "        \n",
    "    print('URL is :' ,blogurl)\n",
    "    try:\n",
    "        count = int(input('输入次数:'))\n",
    "    except ValueError:\n",
    "        print('参数错误')\n",
    "        quit() \n",
    "    if count == 0 or count > 999:\n",
    "        print('次数过大或过小')\n",
    "        quit()\n",
    "    print('次数确认为 %d' % count)\n",
    "    # 获取 博文 列表,由于测试时我的博文只有一页所以 只能获得一页的列表\n",
    "    blog_list = get_blog_list(\"https://youtu.be/RysyB_Zcjlo\")\n",
    "    if len(blog_list) == 0:\n",
    "        print('未找到Blog列表')\n",
    "        quit()\n",
    "    print('启动!!!!!!!!!!!!!!!!!!!!')\n",
    "    # 迭代一下 使用多线程\n",
    "    \n",
    "    index = 0\n",
    "    #maxConnection = 10 \n",
    "    for each_link in range(10):\n",
    "        # 补全头部\n",
    "        each_link = 'https://youtu.be/RysyB_Zcjlo?' + str(each_link)\n",
    "        print (\"===== each_link\",each_link)\n",
    "        #blog_list[index] = each_link\n",
    "        index += 1\n",
    "    # 有多少个帖子就开多少个线程的一半 let's go\n",
    "    pool = ThreadPool(int(len(blog_list) / 2))\n",
    "    results = pool.map(click_blog, blog_list)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    print('完成任务!!!!!!!!!!!!!!!!!!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
